{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641023f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install numpy pandas seaborn tqdm scipy scikit-learn diffprivlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44ae37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as sk_RFC\n",
    "from sklearn.metrics import classification_report, log_loss, roc_curve, roc_auc_score, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c57a2",
   "metadata": {},
   "source": [
    "## Train a Target Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214dc7f",
   "metadata": {},
   "source": [
    "### Get and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ca812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset: https://figshare.le.ac.uk/articles/dataset/Myocardial_infarction_complications_Database/12045261/3\n",
    "# Myocardial infarction complications\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_heart_failure():\n",
    "    df = pd.read_csv(\"https://figshare.le.ac.uk/ndownloader/files/23581310\")\n",
    "    complications = df.columns[-12:]\n",
    "    target_complication = \"ZSN\"  # Chronic heart failure\n",
    "    freq_na_cols = df.columns[df.isna().mean(axis=0) > 0.1]\n",
    "    df = df.drop(columns=freq_na_cols).dropna()\n",
    "\n",
    "    X = df.drop(columns=complications)\n",
    "    y = df[target_complication]\n",
    "    #X = df.drop(columns=target_complication)\n",
    "    #y = df[target_complication]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_diabetes():\n",
    "    df = pd.read_csv('datasets/diabetes.csv')\n",
    "\n",
    "    df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n",
    "    df['Glucose'].fillna(df['Glucose'].mean(), inplace=True)\n",
    "    df['BloodPressure'].fillna(df['BloodPressure'].mean(), inplace=True)\n",
    "    df['SkinThickness'].fillna(df['SkinThickness'].mean(), inplace=True)\n",
    "    df['Insulin'].fillna(df['Insulin'].mean(), inplace=True)\n",
    "    df['BMI'].fillna(df['BMI'].mean(), inplace=True)\n",
    "    \n",
    "    target = \"Outcome\"\n",
    "    X = df.drop(columns=target)\n",
    "    y = df[target]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "#X, y = get_heart_failure()\n",
    "X, y = get_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865c83a",
   "metadata": {},
   "source": [
    "### Fit a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aafbad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, seed=42):\n",
    "    rfc = sk_RFC(\n",
    "        n_estimators=200,\n",
    "        min_samples_split=2,\n",
    "        max_depth=10,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    rfc.fit(X_train, y_train)\n",
    "    return rfc\n",
    "    \n",
    "target_model = train_model(X_train, y_train)\n",
    "\n",
    "# The classifier's accuracy vs. random baseline. We are doing a bit better than the baseline.\n",
    "print(f\"Baseline: {max(y_test.mean(), 1 - y_test.mean()):0.2f}\")\n",
    "print(f\"Our test-score: {target_model.score(X_test, y_test):0.2f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f84e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The classifier's accuracy vs. random baseline. We are doing a bit better than the baseline.\n",
    "print(f\"Baseline: {max(y_test.mean(), 1 - y_test.mean()):0.2f}\")\n",
    "print(f\"Our test-score: {target_model.score(X_test, y_test):0.2f}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc2946",
   "metadata": {},
   "source": [
    "## Measuring Population-Wise Privacy Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b9968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def measure_membership_vulnerability(vals_train, vals_test, target_fpr=0.01):\n",
    "    vals = np.concatenate([vals_train, vals_test])\n",
    "    membership_labels = np.concatenate([[1] * len(vals_train), [0] * len(vals_test)])\n",
    "    best_tpr = 0.0\n",
    "    best_threshold = None\n",
    "    best_preds = np.zeros_like(vals)\n",
    "    # We find a threshold which maximizes attack TPR for a given level of FPR.\n",
    "    for threshold in vals:\n",
    "        tpr = (vals_train > threshold).mean()\n",
    "        fpr = (vals_test > threshold).mean()\n",
    "        if fpr <= target_fpr and tpr > best_tpr:\n",
    "            best_threshold = threshold\n",
    "            best_tpr = tpr\n",
    "            best_preds = (vals > threshold)\n",
    "    \n",
    "    return membership_labels, best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3750837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logit_scale(y_true, y_pred, eps=1e-16):\n",
    "    \"\"\"\n",
    "    Logit scaling from https://arxiv.org/abs/2112.03570\n",
    "    \"\"\"\n",
    "    if isinstance(y_true, np.integer):\n",
    "        y_true = [y_true] * len(y_pred)\n",
    "        \n",
    "    result = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for i in range(len(y_true)):\n",
    "        y = y_true[i]\n",
    "        pred = y_pred[i, y]\n",
    "        result.append(\n",
    "            np.log(np.clip(pred / np.clip(1 - pred, eps, np.inf), eps, np.inf))\n",
    "        )\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd14de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_vals(train_vals, test_vals):\n",
    "    \"\"\"Visualize feature values on train and test data.\"\"\"\n",
    "    return sns.displot(\n",
    "        data=pd.concat([\n",
    "                pd.DataFrame(dict(val=train_vals)).assign(membership=\"train\"),\n",
    "                pd.DataFrame(dict(val=test_vals)).assign(membership=\"test\"),\n",
    "        ]),\n",
    "        x=\"val\",\n",
    "        hue=\"membership\",\n",
    "        kind=\"hist\",\n",
    "        stat=\"probability\",\n",
    "        rug=True,\n",
    "        common_norm=False\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb5d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the features for the membership inference attack.\n",
    "preds_train = target_model.predict_proba(X_train)\n",
    "preds_test = target_model.predict_proba(X_test)\n",
    "\n",
    "logits_train = logit_scale(y_train, preds_train)\n",
    "logits_test = logit_scale(y_test, preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb0c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the features. If it is possible to tell train data from test data, then\n",
    "# our model is vulnerable to membership inference.\n",
    "visualize_vals(logits_train, logits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d894ca5",
   "metadata": {},
   "source": [
    "### What's the membership attack TPR at a given FPR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7311e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_fpr = 0.5\n",
    "membership_labels, membership_preds = measure_membership_vulnerability(\n",
    "    logits_train, logits_test, target_fpr\n",
    ")\n",
    "print(f\"Attack TPR = {(membership_preds[membership_labels == 1] == 1).mean():.2%} @ FPR = {target_fpr:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c4479",
   "metadata": {},
   "source": [
    "### ROC curve of the membership attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f12cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In principle, we do not even need to implement the threshold selection in `measure_membership_vulnerability`.\n",
    "# Here I am just using roc_curve from scikit-learn.\n",
    "\n",
    "fpr, tpr, _ = roc_curve(membership_labels, np.concatenate([logits_train, logits_test]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "roc_df = pd.DataFrame({'FPR': fpr, 'TPR': tpr})\n",
    "\n",
    "sns.lineplot(x='FPR', y='TPR', data=roc_df, label=f\"AUC = {roc_auc:0.2f}\", errorbar=None)\n",
    "sns.lineplot(x=[0, 1], y=[0, 1], color='grey', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d51682",
   "metadata": {},
   "source": [
    "## Protect against leakage\n",
    "\n",
    "Now that we know how much that we're leaking privacy-wise, we can apply the `Opacus / DiffPrivLib` library\n",
    "to our model and see how the ROC curve flattens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95012e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffprivlib.models import RandomForestClassifier as dp_RFC\n",
    "\n",
    "rfc_dp = dp_RFC(\n",
    "    n_estimators=80,\n",
    "#     min_samples_split=2,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    epsilon=1e100,\n",
    "    bounds=(np.min(X_train, axis=0), np.max(X_train, axis=0)),\n",
    "    classes=np.unique(y_train),\n",
    ")\n",
    "\n",
    "target_model = rfc_dp.fit(X_train, y_train)\n",
    "# The classifier's accuracy vs. random baseline. We are doing a bit better than the baseline.\n",
    "print(f\"Baseline: {max(y_test.mean(), 1 - y_test.mean()):0.2f}\")\n",
    "print(f\"Our test-score: {target_model.score(X_test, y_test):0.2f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d804318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features for the membership inference attack.\n",
    "preds_train = target_model.predict_proba(X_train)\n",
    "preds_test = target_model.predict_proba(X_test)\n",
    "\n",
    "logits_train = logit_scale(y_train, preds_train)\n",
    "logits_test = logit_scale(y_test, preds_test)\n",
    "\n",
    "# Visualize the features. If it is possible to tell train data from test data, then\n",
    "# our model is vulnerable to membership inference.\n",
    "visualize_vals(logits_train, logits_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In principle, we do not even need to implement the threshold selection in `measure_membership_vulnerability`.\n",
    "# Here I am just using roc_curve from scikit-learn.\n",
    "fpr, tpr, _ = roc_curve(membership_labels, np.concatenate([logits_train, logits_test]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "roc_df = pd.DataFrame({'FPR': fpr, 'TPR': tpr})\n",
    "\n",
    "sns.lineplot(x='FPR', y='TPR', data=roc_df, label=f\"AUC = {roc_auc:0.2f}\", errorbar=None)\n",
    "sns.lineplot(x=[0, 1], y=[0, 1], color='grey', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e9cc6",
   "metadata": {},
   "source": [
    "## Measuring True Privacy Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125d56f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_feature_func(func, models):\n",
    "    return np.array([func(model) for model in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a0efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_examples_to_attack = 50\n",
    "num_ref_models = 10\n",
    "\n",
    "# Collect some arbitrary target examples to attack.\n",
    "examples_to_attack = []\n",
    "\n",
    "# ...half from the training data.\n",
    "for index in X_train.index[:num_examples_to_attack // 2]:\n",
    "    examples_to_attack.append((index, X_train.loc[index], y_train.loc[index], 1))\n",
    "    \n",
    "# ...half from the test data.\n",
    "for index in X_test.index[:num_examples_to_attack // 2]:\n",
    "    examples_to_attack.append((index, X_test.loc[index], y_test.loc[index], 0))\n",
    "\n",
    "result = []\n",
    "\n",
    "# Now run the re-training attacks!\n",
    "for index, x, y, is_member in tqdm(examples_to_attack):\n",
    "    # First, train a bunch of models without the target example (if it is in fact part of the training data)\n",
    "    out_models = []\n",
    "    for seed in range(num_ref_models):\n",
    "        ref_model = train_model(\n",
    "            X_train.drop(index=[index], errors=\"ignore\"),\n",
    "            y_train.drop(index=[index], errors=\"ignore\"),\n",
    "            seed=seed\n",
    "        )\n",
    "        out_models.append(ref_model)\n",
    "    \n",
    "    # Compute the attack features.\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        preds_in = compute_feature_func(lambda model: model.predict_proba([x])[0], [target_model])\n",
    "        preds_out = compute_feature_func(lambda model: model.predict_proba([x])[0], out_models)\n",
    "    \n",
    "    logit_in = logit_scale(y, preds_in)[0]\n",
    "    logits_out = logit_scale(y, preds_out)\n",
    "    \n",
    "    # Next, we run a parametric test. We assume that \"out\" logits are Gaussian-distributed, \n",
    "    # so compute their mean and variance.\n",
    "    logits_out_mean = np.mean(logits_out)\n",
    "    logits_out_var = np.var(logits_out)\n",
    "    \n",
    "    # The parametric test is computing the probability that the \"out\" logits are less than \"in\" logit,\n",
    "    # which means that we predict the target record as a member:\n",
    "    # \n",
    "    #   Pr[logit_out <= logit_in], where logit_out ~ Normal(mean, var) with mean and var\n",
    "    #   estimated from reference models.\n",
    "    #\n",
    "    # See https://arxiv.org/abs/2112.03570, Eq. (4)\n",
    "    prob = stats.norm(logits_out_mean, logits_out_var).cdf(logit_in) \n",
    "    \n",
    "    result.append(dict(\n",
    "        target_index=index,\n",
    "        is_member=is_member,\n",
    "        prob=prob,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920bd46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(pd.DataFrame(result).is_member, pd.DataFrame(result).prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "roc_df = pd.DataFrame({'FPR': fpr, 'TPR': tpr})\n",
    "\n",
    "sns.lineplot(x='FPR', y='TPR', data=roc_df, label=f\"AUC = {roc_auc:0.2f}\", errorbar=None)\n",
    "sns.lineplot(x=[0, 1], y=[0, 1], color='grey', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ee293-5e2b-46c8-8ab4-a5966028dbab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641023f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run 2-population-attack.ipynb\n",
    "verbose_population_diffpriv = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d51682",
   "metadata": {},
   "source": [
    "## Protect against leakage\n",
    "\n",
    "Now that we know how much that we're leaking privacy-wise, we can apply the `Opacus / DiffPrivLib` library\n",
    "to our model and see how the ROC curve flattens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95012e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffprivlib.models import RandomForestClassifier as dp_RFC\n",
    "\n",
    "def train_model_dp(X_train, y_train, seed=42):\n",
    "    rfc_dp = dp_RFC(\n",
    "        n_estimators=100,\n",
    "        max_depth=12,\n",
    "        random_state=42,\n",
    "        epsilon=np.inf,\n",
    "        bounds=(np.min(X_train, axis=0), np.max(X_train, axis=0)),\n",
    "        classes=np.unique(y_train),\n",
    "    )\n",
    "    return rfc_dp.fit(X_train, y_train)\n",
    "\n",
    "target_model_dp = train_model_dp(X_train, y_train)\n",
    "# The classifier's accuracy vs. random baseline. We are doing a bit better than the baseline.\n",
    "print(f\"Baseline: {max(y_test.mean(), 1 - y_test.mean()):0.2f}\")\n",
    "print(f\"Our test-score: {target_model.score(X_test, y_test):0.2f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d804318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features for the membership inference attack.\n",
    "logits_train_dp = logits(target_model_dp, X_train, y_train)\n",
    "logits_test_dp = logits(target_model_dp, X_test, y_test)\n",
    "\n",
    "if verbose_population_diffpriv:\n",
    "    plot_rfc_auroc(y_test, target_model_dp.predict_proba(X=X_test)[:,1], \"ROC of classifier using DP\")\n",
    "    # Visualize the features. If it is possible to tell train data from test data, then\n",
    "    # our model is vulnerable to membership inference.\n",
    "    visualize_vals(logits_train_dp, logits_test_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose_population_diffpriv:\n",
    "    membership_labels = np.concatenate([[1] * len(logits_train_dp), [0] * len(logits_test_dp)])\n",
    "    plot_rfc_auroc(membership_labels, np.concatenate([logits_train_dp, logits_test_dp]),\n",
    "                  \"ROC of Population attack metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a02d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a28cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

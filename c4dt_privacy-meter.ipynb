{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641023f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install numpy pandas seaborn tqdm scipy scikit-learn privacy-meter tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef44ae37",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, log_loss, roc_curve, roc_auc_score, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c57a2",
   "metadata": {},
   "source": [
    "## Train a Target Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214dc7f",
   "metadata": {},
   "source": [
    "### Get and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987ca812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 124)\n",
      "(1074, 107)\n",
      "268 269 537\n"
     ]
    }
   ],
   "source": [
    "# Dataset: https://figshare.le.ac.uk/articles/dataset/Myocardial_infarction_complications_Database/12045261/3\n",
    "# Myocardial infarction complications\n",
    "df = pd.read_csv(\"https://figshare.le.ac.uk/ndownloader/files/23581310\")\n",
    "print(df.shape)\n",
    "\n",
    "complications = df.columns[-12:]\n",
    "target_complication = \"ZSN\"  # Chronic heart failure\n",
    "freq_na_cols = df.columns[df.isna().mean(axis=0) > 0.1]\n",
    "df = df.drop(columns=freq_na_cols).dropna()\n",
    "print(df.shape)\n",
    "\n",
    "X = df.drop(columns=complications)\n",
    "y = df[target_complication]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=42)\n",
    "X_test, X_population, y_test, y_population = train_test_split(X_test, y_test, test_size = 0.666, random_state=42)\n",
    "print(len(X_train), len(X_test), len(X_population))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865c83a",
   "metadata": {},
   "source": [
    "### Fit a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95aafbad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, seed=42):\n",
    "    rfc = RandomForestClassifier(\n",
    "        n_estimators=80,\n",
    "        min_samples_split=2,\n",
    "        max_depth=10,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    rfc.fit(X_train, y_train)\n",
    "    return rfc\n",
    "    \n",
    "target_model = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f84e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The classifier's accuracy vs. random baseline. We are doing a bit better than the baseline.\n",
    "print(f\"Baseline: {max(y_test.mean(), 1 - y_test.mean()):0.2f}\")\n",
    "print(f\"Our test-score: {target_model.score(X_test, y_test):0.2f}\" )\n",
    "print(f\"Our population-score: {target_model.score(X_population, y_population):0.2f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_meter.dataset import Dataset\n",
    "\n",
    "# create the target model's dataset\n",
    "train_ds = {'x': X_train, 'y': y_train}\n",
    "test_ds = {'x': X_test, 'y': y_test}\n",
    "target_dataset = Dataset(\n",
    "    data_dict={'train': train_ds, 'test': test_ds},\n",
    "    default_input='x', default_output='y'\n",
    ")\n",
    "\n",
    "# create the reference dataset\n",
    "population_ds = {'x': X_population, 'y': y_population}\n",
    "reference_dataset = Dataset(\n",
    "    # this is the default mapping that a Metric will look for\n",
    "    # in a reference dataset\n",
    "    data_dict={'train': population_ds},\n",
    "    default_input='x', default_output='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8aeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_meter.model import TensorflowModel\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "target_model = TensorflowModel(model_obj=target_model, loss_fn=loss_fn)\n",
    "\n",
    "from privacy_meter.audit import Audit, MetricEnum\n",
    "from privacy_meter.audit_report import ROCCurveReport, SignalHistogramReport\n",
    "from privacy_meter.constants import InferenceGame\n",
    "from privacy_meter.information_source import InformationSource\n",
    "\n",
    "target_info_source = InformationSource(\n",
    "    models=[target_model], \n",
    "    datasets=[target_dataset]\n",
    ")\n",
    "\n",
    "reference_info_source = InformationSource(\n",
    "    models=[target_model],\n",
    "    datasets=[reference_dataset]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc2946",
   "metadata": {},
   "source": [
    "## Measuring Population-Wise Privacy Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b9968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def measure_membership_vulnerability(vals_train, vals_test, target_fpr=0.01):\n",
    "    vals = np.concatenate([vals_train, vals_test])\n",
    "    membership_labels = np.concatenate([[1] * len(vals_train), [0] * len(vals_test)])\n",
    "    best_tpr = 0.0\n",
    "    best_threshold = None\n",
    "    best_preds = np.zeros_like(vals)\n",
    "    # We find a threshold which maximizes attack TPR for a given level of FPR.\n",
    "    for threshold in vals:\n",
    "        tpr = (vals_train > threshold).mean()\n",
    "        fpr = (vals_test > threshold).mean()\n",
    "        if fpr <= target_fpr and tpr > best_tpr:\n",
    "            best_threshold = threshold\n",
    "            best_tpr = tpr\n",
    "            best_preds = (vals > threshold)\n",
    "    \n",
    "    return membership_labels, best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3750837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logit_scale(y_true, y_pred, eps=1e-16):\n",
    "    \"\"\"\n",
    "    Logit scaling from https://arxiv.org/abs/2112.03570\n",
    "    \"\"\"\n",
    "    if isinstance(y_true, np.integer):\n",
    "        y_true = [y_true] * len(y_pred)\n",
    "        \n",
    "    result = []\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for i in range(len(y_true)):\n",
    "        y = y_true[i]\n",
    "        pred = y_pred[i, y]\n",
    "        result.append(\n",
    "            np.log(np.clip(pred / np.clip(1 - pred, eps, np.inf), eps, np.inf))\n",
    "        )\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd14de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_vals(train_vals, test_vals):\n",
    "    \"\"\"Visualize feature values on train and test data.\"\"\"\n",
    "    return sns.displot(\n",
    "        data=pd.concat([\n",
    "                pd.DataFrame(dict(val=train_vals)).assign(membership=\"train\"),\n",
    "                pd.DataFrame(dict(val=test_vals)).assign(membership=\"test\"),\n",
    "        ]),\n",
    "        x=\"val\",\n",
    "        hue=\"membership\",\n",
    "        kind=\"hist\",\n",
    "        stat=\"probability\",\n",
    "        rug=True,\n",
    "        common_norm=False\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb5d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the features for the membership inference attack.\n",
    "preds_train = target_model.predict_proba(X_train)\n",
    "preds_test = target_model.predict_proba(X_test)\n",
    "\n",
    "logits_train = logit_scale(y_train, preds_train)\n",
    "logits_test = logit_scale(y_test, preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb0c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the features. If it is possible to tell train data from test data, then\n",
    "# our model is vulnerable to membership inference.\n",
    "visualize_vals(logits_train, logits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d894ca5",
   "metadata": {},
   "source": [
    "### What's the membership attack TPR at a given FPR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7311e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_fpr = 0.5\n",
    "membership_labels, membership_preds = measure_membership_vulnerability(\n",
    "    logits_train, logits_test, target_fpr\n",
    ")\n",
    "print(f\"Attack TPR = {(membership_preds[membership_labels == 1] == 1).mean():.2%} @ FPR = {target_fpr:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c4479",
   "metadata": {},
   "source": [
    "### ROC curve of the membership attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f12cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In principle, we do not even need to implement the threshold selection in `measure_membership_vulnerability`.\n",
    "# Here I am just using roc_curve from scikit-learn.\n",
    "\n",
    "fpr, tpr, _ = roc_curve(membership_labels, np.concatenate([logits_train, logits_test]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "roc_df = pd.DataFrame({'FPR': fpr, 'TPR': tpr})\n",
    "\n",
    "sns.lineplot(x='FPR', y='TPR', data=roc_df, label=f\"AUC = {roc_auc:0.2f}\", errorbar=None)\n",
    "sns.lineplot(x=[0, 1], y=[0, 1], color='grey', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e9cc6",
   "metadata": {},
   "source": [
    "## Measuring True Privacy Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125d56f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_feature_func(func, models):\n",
    "    return np.array([func(model) for model in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a0efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_examples_to_attack = 50\n",
    "num_ref_models = 10\n",
    "\n",
    "# Collect some arbitrary target examples to attack.\n",
    "examples_to_attack = []\n",
    "\n",
    "# ...half from the training data.\n",
    "for index in X_train.index[:num_examples_to_attack // 2]:\n",
    "    examples_to_attack.append((index, X_train.loc[index], y_train.loc[index], 1))\n",
    "    \n",
    "# ...half from the test data.\n",
    "for index in X_test.index[:num_examples_to_attack // 2]:\n",
    "    examples_to_attack.append((index, X_test.loc[index], y_test.loc[index], 0))\n",
    "\n",
    "result = []\n",
    "\n",
    "# Now run the re-training attacks!\n",
    "for index, x, y, is_member in tqdm(examples_to_attack):\n",
    "    # First, train a bunch of models without the target example (if it is in fact part of the training data)\n",
    "    out_models = []\n",
    "    for seed in range(num_ref_models):\n",
    "        ref_model = train_model(\n",
    "            X_train.drop(index=[index], errors=\"ignore\"),\n",
    "            y_train.drop(index=[index], errors=\"ignore\"),\n",
    "            seed=seed\n",
    "        )\n",
    "        out_models.append(ref_model)\n",
    "    \n",
    "    # Compute the attack features.\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        preds_in = compute_feature_func(lambda model: model.predict_proba([x])[0], [target_model])\n",
    "        preds_out = compute_feature_func(lambda model: model.predict_proba([x])[0], out_models)\n",
    "    \n",
    "    logit_in = logit_scale(y, preds_in)[0]\n",
    "    logits_out = logit_scale(y, preds_out)\n",
    "    \n",
    "    # Next, we run a parametric test. We assume that \"out\" logits are Gaussian-distributed, \n",
    "    # so compute their mean and variance.\n",
    "    logits_out_mean = np.mean(logits_out)\n",
    "    logits_out_var = np.var(logits_out)\n",
    "    \n",
    "    # The parametric test is computing the probability that the \"out\" logits are less than \"in\" logit,\n",
    "    # which means that we predict the target record as a member:\n",
    "    # \n",
    "    #   Pr[logit_out <= logit_in], where logit_out ~ Normal(mean, var) with mean and var\n",
    "    #   estimated from reference models.\n",
    "    #\n",
    "    # See https://arxiv.org/abs/2112.03570, Eq. (4)\n",
    "    prob = stats.norm(logits_out_mean, logits_out_var).cdf(logit_in) \n",
    "    \n",
    "    result.append(dict(\n",
    "        target_index=index,\n",
    "        is_member=is_member,\n",
    "        prob=prob,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920bd46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(pd.DataFrame(result).is_member, pd.DataFrame(result).prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "roc_df = pd.DataFrame({'FPR': fpr, 'TPR': tpr})\n",
    "\n",
    "sns.lineplot(x='FPR', y='TPR', data=roc_df, label=f\"AUC = {roc_auc:0.2f}\", errorbar=None)\n",
    "sns.lineplot(x=[0, 1], y=[0, 1], color='grey', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ee293-5e2b-46c8-8ab4-a5966028dbab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
